{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import DataStructs\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append(\"/home/user-home/yujie/0_PBCNetv2/0_PBCNET/model_code/\")\n",
    "code_path = '/home/user-home/yujie/0_PBCNetv2/0_PBCNET/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ =\"/home/user-home/yujie/0_PBCNetv2/0_PBCNET/Result_in_paper/2.5_section/enpp1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance_matrix\n",
    "from Bio.PDB import *\n",
    "from Bio.PDB.PDBIO import Select\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "\n",
    "\n",
    "def extract(ligand, pdb):\n",
    "    parser = PDBParser()\n",
    "    if not os.path.exists(pdb) :\n",
    "        print(\"The path of PDB is not available.\")\n",
    "        return None\n",
    "\n",
    "    structure = parser.get_structure(\"protein\", pdb)\n",
    "\n",
    "    lp = []\n",
    "    for l in ligand:\n",
    "        lp.append(l.GetConformer().GetPositions())\n",
    "    ligand_positions=np.concatenate(lp)\n",
    "\n",
    "    class ResidueSelect(Select):\n",
    "        def accept_residue(self, residue):\n",
    "            residue_positions = np.array([np.array(list(atom.get_vector())) \\\n",
    "                for atom in residue.get_atoms() if \"H\" not in atom.get_id()])\n",
    "            if len(residue_positions.shape) < 2:\n",
    "                print(residue)\n",
    "                return 0\n",
    "            min_dis = np.min(distance_matrix(residue_positions, ligand_positions))\n",
    "            if min_dis < 8.0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "    io = PDBIO()\n",
    "    io.set_structure(structure)\n",
    "    fn =  pdb.replace('protein.pdb', 'pocket.pdb')\n",
    "    io.save(fn, ResidueSelect())  \n",
    "\n",
    "\n",
    "def pocket_extract(sdf_files, protein_file):\n",
    "\n",
    "    ligands = []\n",
    "    for a in sdf_files:\n",
    "        mol = Chem.MolFromMolFile(a)\n",
    "        if mol is not None:\n",
    "            ligands.append(mol)\n",
    "        else:\n",
    "            print(f\"{a} connot be read by rdkit!\")\n",
    "\n",
    "    extract(ligands,protein_file)\n",
    "\n",
    "\n",
    "    print(\"The pocket has been extracted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pocket has been extracted successfully.\n"
     ]
    }
   ],
   "source": [
    "d = dir_\n",
    "sdfs = [d+i for i in os.listdir(d) if i.endswith('.sdf')]\n",
    "\n",
    "pocket_extract(sdfs,f'{d}/protein.pdb')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== graph generation ======\n",
    "from rdkit.Chem.rdchem import BondType as BT\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import BRICS\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import warnings\n",
    "import multiprocessing\n",
    "import dgl\n",
    "from Bio.PDB.PDBParser import PDBParser\n",
    "\n",
    "def setup_cpu(cpu_num):\n",
    "    os.environ['OMP_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['OPENBLAS_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['MKL_NUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['VECLIB_MAXIMUM_THREADS'] = str(cpu_num)\n",
    "    os.environ['NUMEXPR_NUM_THREADS'] = str(cpu_num)\n",
    "    # torch.set_num_threads(cpu_num)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "allowable_features = {\n",
    "    # 'possible_atomic_num_list': list(range(1, 119)) + ['misc'],\n",
    "    'possible_chirality_list': ['CHI_UNSPECIFIED',\n",
    "                                'CHI_TETRAHEDRAL_CW',\n",
    "                                'CHI_TETRAHEDRAL_CCW',\n",
    "                                'CHI_OTHER'],\n",
    "    'possible_degree_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'misc'],\n",
    "    'possible_numring_list': [0, 1, 2, 3, 4, 5, 6, 'misc'],\n",
    "    'possible_implicit_valence_list': [0, 1, 2, 3, 4, 5, 6, 'misc'],\n",
    "    'possible_formal_charge_list': [-5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 'misc'],\n",
    "    'possible_numH_list': [0, 1, 2, 3, 4, 5, 6, 7, 8, 'misc'],\n",
    "    'possible_number_radical_e_list': [0, 1, 2, 3, 4, 'misc'],\n",
    "    'possible_hybridization_list': ['SP', 'SP2', 'SP3', 'SP3D', 'SP3D2', 'misc'],\n",
    "    'possible_is_aromatic_list': [False, True],\n",
    "    'possible_is_in_ring3_list': [False, True],\n",
    "    'possible_is_in_ring4_list': [False, True],\n",
    "    'possible_is_in_ring5_list': [False, True],\n",
    "    'possible_is_in_ring6_list': [False, True],\n",
    "    'possible_is_in_ring7_list': [False, True],\n",
    "    'possible_is_in_ring8_list': [False, True]\n",
    "    }\n",
    "\n",
    "def safe_index(l, e):\n",
    "    \"\"\" Return index of element e in list l. If e is not present, return the last index \"\"\"\n",
    "    try:\n",
    "        return l.index(e)\n",
    "    except:\n",
    "        return len(l) - 1\n",
    "\n",
    "# ====== for pockt group =======\n",
    "one_to_three = {\"A\" : \"ALA\",\n",
    "              \"C\" : \"CYS\",\n",
    "              \"D\" : \"ASP\",\n",
    "              \"E\" : \"GLU\",\n",
    "              \"F\" : \"PHE\",\n",
    "              \"G\" : \"GLY\",\n",
    "              \"H\" : \"HIS\",\n",
    "              \"I\" : \"ILE\",\n",
    "              \"K\" : \"LYS\",\n",
    "              \"L\" : \"LEU\",\n",
    "              \"M\" : \"MET\",\n",
    "              \"N\" : \"ASN\",\n",
    "              \"P\" : \"PRO\",\n",
    "              \"Q\" : \"GLN\",\n",
    "              \"R\" : \"ARG\",\n",
    "              \"S\" : \"SER\",\n",
    "              \"T\" : \"THR\",\n",
    "              \"V\" : \"VAL\",\n",
    "              \"W\" : \"TRP\",\n",
    "              \"Y\" : \"TYR\",\n",
    "              \"B\" : \"ASX\",\n",
    "              \"Z\" : \"GLX\",\n",
    "              \"X\" : \"UNK\",\n",
    "              \"*\" : \" * \"}\n",
    "\n",
    "three_to_one = {}\n",
    "for _key, _value in one_to_three.items():\n",
    "    three_to_one[_value] = _key\n",
    "three_to_one[\"SEC\"] = \"C\"\n",
    "three_to_one[\"MSE\"] = \"M\"\n",
    "\n",
    "pro_res_table = ['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y',\n",
    "                 'X']\n",
    "pro_res_aliphatic_table = ['A', 'I', 'L', 'M', 'V']\n",
    "pro_res_aromatic_table = ['F', 'W', 'Y']\n",
    "pro_res_polar_neutral_table = ['C', 'N', 'Q', 'S', 'T']\n",
    "pro_res_acidic_charged_table = ['D', 'E']\n",
    "pro_res_basic_charged_table = ['H', 'K', 'R']\n",
    "\n",
    "def prop(residue):\n",
    "    res_property1 = [1 if residue in pro_res_aliphatic_table else 0, 1 if residue in pro_res_aromatic_table else 0,\n",
    "                        1 if residue in pro_res_polar_neutral_table else 0,\n",
    "                        1 if residue in pro_res_acidic_charged_table else 0,\n",
    "                        1 if residue in pro_res_basic_charged_table else 0, 1]\n",
    "    return res_property1\n",
    "\n",
    "def res_pocket(p):\n",
    "\n",
    "    parser = PDBParser(PERMISSIVE=1)\n",
    "    s = parser.get_structure('a', p)\n",
    "   \n",
    "    atom2res_idx = []  \n",
    "    res_name = []\n",
    "    count = -1\n",
    "    for model in s:\n",
    "        for chain in model:\n",
    "            for residue in chain:\n",
    "                count += 1\n",
    "                name = residue.get_resname()\n",
    "                for atom in residue:\n",
    "                    if atom.get_fullname() [0] != 'H' and atom.get_fullname()[1] != 'H':\n",
    "                        atom2res_idx.append(count)\n",
    "                        res_name.append(name)\n",
    "\n",
    "    res3 = [three_to_one[i] if i in three_to_one.keys() else 'X' for i in res_name]\n",
    "\n",
    "    res_type = [pro_res_table.index(i) for i in res3]  \n",
    "    res_prop  = [prop(i) for i in res3]  \n",
    "    assert len(atom2res_idx) == len(res_type) == len(res_prop)\n",
    "    return atom2res_idx, res_type, res_prop\n",
    "\n",
    "\n",
    "def lig_atom_featurizer(mol):\n",
    "    ringinfo = mol.GetRingInfo()\n",
    "    atom_features_list = []\n",
    "    for idx, atom in enumerate(mol.GetAtoms()):\n",
    "        atom_features_list.append([\n",
    "            safe_index(allowable_features['possible_chirality_list'], str(atom.GetChiralTag())),\n",
    "            safe_index(allowable_features['possible_degree_list'], atom.GetTotalDegree()),\n",
    "            safe_index(allowable_features['possible_formal_charge_list'], atom.GetFormalCharge()),\n",
    "            safe_index(allowable_features['possible_numH_list'], atom.GetTotalNumHs()),\n",
    "            safe_index(allowable_features['possible_hybridization_list'], str(atom.GetHybridization())),\n",
    "            allowable_features['possible_is_aromatic_list'].index(atom.GetIsAromatic()),\n",
    "            safe_index(allowable_features['possible_implicit_valence_list'], atom.GetImplicitValence()),\n",
    "            safe_index(allowable_features['possible_number_radical_e_list'], atom.GetNumRadicalElectrons()),\n",
    "            safe_index(allowable_features['possible_numring_list'], ringinfo.NumAtomRings(idx)),\n",
    "            allowable_features['possible_is_in_ring3_list'].index(ringinfo.IsAtomInRingOfSize(idx, 3)),\n",
    "            allowable_features['possible_is_in_ring4_list'].index(ringinfo.IsAtomInRingOfSize(idx, 4)),\n",
    "            allowable_features['possible_is_in_ring5_list'].index(ringinfo.IsAtomInRingOfSize(idx, 5)),\n",
    "            allowable_features['possible_is_in_ring6_list'].index(ringinfo.IsAtomInRingOfSize(idx, 6)),\n",
    "            allowable_features['possible_is_in_ring7_list'].index(ringinfo.IsAtomInRingOfSize(idx, 7)),\n",
    "            allowable_features['possible_is_in_ring8_list'].index(ringinfo.IsAtomInRingOfSize(idx, 8)),\n",
    "        ])\n",
    "\n",
    "    return atom_features_list\n",
    "\n",
    "\n",
    "def group_complex(ligand, pocket_dir):\n",
    "    brics_index = brics_decomp(ligand)\n",
    "    group_index = [0 for _ in range(len(ligand.GetAtoms()))]\n",
    "    group_type = [0 for _ in range(len(ligand.GetAtoms()))]   \n",
    "    group_prop = [[0,0,0,0,0,0] for _ in range(len(ligand.GetAtoms()))] \n",
    "\n",
    "    if type(brics_index) == type(tuple(('a', 'b', 'c'))):\n",
    "        brics_index = brics_index[0]\n",
    "\n",
    "    for i, idx in enumerate(brics_index):\n",
    "        for idx_ in idx:\n",
    "            group_index[idx_] = i\n",
    "\n",
    "    atom2res_idx, res_type, res_prop = res_pocket(pocket_dir)\n",
    "\n",
    "    atom2res_idx = [i+len(brics_index) for i in atom2res_idx]\n",
    "    res_type = [i+1 for i in res_type] \n",
    "\n",
    "    group_index.extend(atom2res_idx)\n",
    "    group_type.extend(res_type)\n",
    "    group_prop.extend(res_prop)\n",
    "\n",
    "    return torch.tensor(group_index,dtype=torch.float32), torch.tensor(group_type,dtype=torch.float32), torch.tensor(group_prop, dtype=torch.float32)\n",
    "\n",
    "\n",
    "def atom_type(ligand,pocket):\n",
    "\n",
    "    l_atom = np.array([i.GetAtomicNum() for i in ligand.GetAtoms()])\n",
    "    lig_atom = [1 for _ in l_atom]\n",
    "    p_atom = np.array([i.GetAtomicNum() for i in pocket.GetAtoms()])\n",
    "    pock_atom = [0 for _ in p_atom]\n",
    "    complex_atom = torch.tensor(np.concatenate([l_atom, p_atom]))\n",
    "    type_for_mask = torch.tensor(np.concatenate([lig_atom, pock_atom]))\n",
    "    z = complex_atom\n",
    "    return z, type_for_mask\n",
    "\n",
    "\n",
    "\n",
    "bonds = {BT.SINGLE: 0, BT.DOUBLE: 1, BT.TRIPLE: 2, BT.AROMATIC: 3} \n",
    "\n",
    "def bond_featurizer(ligand, pocket, index):\n",
    "    bond_type = []\n",
    "    num_atoms = len(ligand.GetAtoms())\n",
    "    for a1, a2 in zip(index[0], index[1]):\n",
    "        if a1 < num_atoms and a2 < num_atoms:   \n",
    "            bond = ligand.GetBondBetweenAtoms(a1, a2)\n",
    "            if bond is None:\n",
    "                bond_type.append(4)   # distance bond\n",
    "            else:\n",
    "                bond_type.append(bonds[bond.GetBondType()])\n",
    "        elif a1 >= num_atoms and a2 >= num_atoms: \n",
    "            a1 = a1 - num_atoms\n",
    "            a2 = a2 - num_atoms\n",
    "            bond = pocket.GetBondBetweenAtoms(a1, a2)\n",
    "            if bond is None:\n",
    "                bond_type.append(5)   # distance bond\n",
    "            else:\n",
    "                bond_type.append(bonds[bond.GetBondType()])\n",
    "        else:\n",
    "            bond_type.append(6)\n",
    "    return torch.tensor(bond_type, dtype=torch.float32)\n",
    "    \n",
    "\n",
    "# ===== mol split =====\n",
    "def brics_decomp(mol):\n",
    "    n_atoms = mol.GetNumAtoms()\n",
    "    if n_atoms == 1:\n",
    "        return [[0]], []\n",
    "\n",
    "    cliques = []\n",
    "    breaks = []\n",
    "    for bond in mol.GetBonds():\n",
    "        a1 = bond.GetBeginAtom().GetIdx()\n",
    "        a2 = bond.GetEndAtom().GetIdx()\n",
    "        cliques.append([a1, a2])\n",
    "\n",
    "    res = list(BRICS.FindBRICSBonds(mol))\n",
    "    if len(res) == 0:\n",
    "        return [list(range(n_atoms))], []\n",
    "    else:\n",
    "        for bond in res:\n",
    "            if [bond[0][0], bond[0][1]] in cliques:\n",
    "                cliques.remove([bond[0][0], bond[0][1]])\n",
    "            else:\n",
    "                cliques.remove([bond[0][1], bond[0][0]])\n",
    "            cliques.append([bond[0][0]])\n",
    "            cliques.append([bond[0][1]])\n",
    "\n",
    "    # merge cliques\n",
    "    for c in range(len(cliques) - 1):\n",
    "        if c >= len(cliques):\n",
    "            break\n",
    "        for k in range(c + 1, len(cliques)):\n",
    "            if k >= len(cliques):\n",
    "                break\n",
    "            if len(set(cliques[c]) & set(cliques[k])) > 0:\n",
    "                cliques[c] = list(set(cliques[c]) | set(cliques[k]))\n",
    "                cliques[k] = []\n",
    "        cliques = [c for c in cliques if len(c) > 0]\n",
    "    cliques = [c for c in cliques if len(c) > 0]\n",
    "\n",
    "    # edges\n",
    "    edges = []\n",
    "    for bond in res:\n",
    "        for c in range(len(cliques)):\n",
    "            if bond[0][0] in cliques[c]:\n",
    "                c1 = c\n",
    "            if bond[0][1] in cliques[c]:\n",
    "                c2 = c\n",
    "        edges.append((c1, c2))\n",
    "    for bond in breaks:\n",
    "        for c in range(len(cliques)):\n",
    "            if bond[0] in cliques[c]:\n",
    "                c1 = c\n",
    "            if bond[1] in cliques[c]:\n",
    "                c2 = c\n",
    "        edges.append((c1, c2))\n",
    "\n",
    "    return cliques\n",
    "\n",
    "\n",
    "def Graph_Information(ligand_file, pocket_file):\n",
    "\n",
    "    ligand = Chem.MolFromMolFile(ligand_file)\n",
    "    ligand = Chem.RemoveAllHs(ligand)\n",
    "    pocket = Chem.MolFromPDBFile(pocket_file)\n",
    "    pocket = Chem.RemoveAllHs(pocket)\n",
    "\n",
    "\n",
    "    graph_data = {\n",
    "                ('atom', 'int', 'atom'): ([], []),\n",
    "                ('atom', 'ind', 'atom'): ([], [])\n",
    "\n",
    "                }\n",
    "    G = dgl.heterograph(graph_data)\n",
    "\n",
    "    # ====== 获得原子类型及来源信息 =======\n",
    "    x, type_for_mask = atom_type(ligand, pocket)\n",
    "    G.add_nodes(x.shape[0])\n",
    "    \n",
    "    # ====== 获得其余原子标量信息 =======\n",
    "    lig_atom_feature = lig_atom_featurizer(ligand)\n",
    "    pock_atom_feature = lig_atom_featurizer(pocket)\n",
    "    atom_scalar = torch.tensor(np.concatenate([lig_atom_feature, pock_atom_feature]), dtype=torch.float32)\n",
    "\n",
    "    # ===== 基于group的信息 =====\n",
    "    index, g_type, g_prop = group_complex(ligand, pocket_file)\n",
    "\n",
    "    # ====== 获得原子坐标 ======\n",
    "    coor_lig = ligand.GetConformer().GetPositions()\n",
    "    coor_pock = pocket.GetConformer().GetPositions()\n",
    "    pos = np.concatenate([coor_lig, coor_pock])\n",
    "    pos = torch.tensor(pos, dtype=torch.float32)\n",
    "    G.nodes['atom'].data['pos'] = pos\n",
    "    \n",
    "    # ====== type1: 小分子内部边 ======  \n",
    "    # (ind = independent)\n",
    "    for i in range(len(coor_lig)):\n",
    "        for j in range(i + 1, len(coor_lig)):\n",
    "            dist = np.linalg.norm(coor_lig[i] - coor_lig[j])\n",
    "            if dist <= 5 and dist > 0:\n",
    "                # # G.add_edges(i, j, etype='ind')\n",
    "                # # G.add_edges(j, i, etype='ind')\n",
    "                G.add_edges(i, j, etype='int')\n",
    "                G.add_edges(j, i, etype='int')\n",
    "                continue\n",
    "\n",
    "    # ====== type2: 蛋白口袋共价边 ======  \n",
    "    # (ind = independent)\n",
    "    for bond in pocket.GetBonds():\n",
    "        start_atom = bond.GetBeginAtomIdx()\n",
    "        end_atom = bond.GetEndAtomIdx()\n",
    "        # G.add_edges(start_atom + len(coor_lig), end_atom + len(coor_lig), etype='ind')\n",
    "        # G.add_edges(end_atom + len(coor_lig), start_atom + len(coor_lig), etype='ind')\n",
    "        G.add_edges(start_atom + len(coor_lig), end_atom + len(coor_lig), etype='int')\n",
    "        G.add_edges(end_atom + len(coor_lig), start_atom + len(coor_lig), etype='int')\n",
    "        continue\n",
    "\n",
    "\n",
    "    # ====== type3: 蛋白和小分子的距离边 ======  \n",
    "    # (int = interaction)\n",
    "    for i in range(len(coor_lig)):\n",
    "        for j in range(len(coor_pock)):\n",
    "            dist = np.linalg.norm(coor_lig[i] - coor_pock[j])\n",
    "            if dist <= 5 and dist > 0:\n",
    "                G.add_edges(i, len(coor_lig) + j, etype='int')\n",
    "                G.add_edges(len(coor_lig) + j, i, etype='int')\n",
    "                continue\n",
    "    \n",
    "    # ====== type4: 蛋白靠近表面的原子与其余蛋白原子的距离边 ======  \n",
    "    # (int = interaction)\n",
    "    # 找到所有与小分子连接的蛋白质原子\n",
    "    connected_protein_atoms = set(j for i in range(len(coor_lig)) for j in G.successors(i,etype='int') if j >= len(coor_lig))\n",
    "    # print(connected_protein_atoms)\n",
    "    for i in connected_protein_atoms:\n",
    "        for j in range(len(coor_pock)):\n",
    "            dist = np.linalg.norm(coor_pock[i - len(coor_lig)] - coor_pock[j])\n",
    "            # print(G.has_edges_between(i, len(coor_lig) + j, etype='ind').item())\n",
    "            if  (dist <= 3) and (dist > 0) and  (G.has_edges_between(i, len(coor_lig) + j, etype='ind').item() is False):\n",
    "                # G.add_edges(i, len(coor_lig) + j, etype='ind')\n",
    "                # G.add_edges(len(coor_lig) + j, i, etype='ind')\n",
    "                G.add_edges(i, len(coor_lig) + j, etype='int')\n",
    "                G.add_edges(len(coor_lig) + j, i, etype='int')\n",
    "                continue\n",
    "\n",
    "    edge_index_int = [G.edges(etype='int')[0].detach().numpy().tolist(), G.edges(etype='int')[1].detach().numpy().tolist()]\n",
    "    edge_index_ind = [G.edges(etype='ind')[0].detach().numpy().tolist(), G.edges(etype='ind')[1].detach().numpy().tolist()]\n",
    "\n",
    "    # ====== 获得边的标量信息(边类型) ========\n",
    "    bond_type_int = bond_featurizer(ligand, pocket, edge_index_int)\n",
    "    bond_type_ind = bond_featurizer(ligand, pocket, edge_index_ind)\n",
    "    \n",
    "    # ====== 其中x是原子类型， atom_scalar是除了原子类型之外的原子信息 ========\n",
    "    #index, g_type, g_prop\n",
    "    G.nodes['atom'].data['res_idx'] = index\n",
    "    G.nodes['atom'].data['res_type'] = g_type\n",
    "    G.nodes['atom'].data['res_prop'] = g_prop\n",
    "\n",
    "    G.nodes['atom'].data['x'] = x\n",
    "    G.nodes['atom'].data['pos'] = pos\n",
    "    G.nodes['atom'].data['type'] =type_for_mask\n",
    "    G.nodes['atom'].data['atom_scalar'] = atom_scalar\n",
    "    G.edges['ind'].data['bond_scalar'] = bond_type_ind\n",
    "    G.edges['int'].data['bond_scalar'] = bond_type_int\n",
    "    return G\n",
    "\n",
    "\n",
    "def graph_save(ligand_file, pock_file, pickle_save):\n",
    "    \n",
    "    if not (os.path.exists(ligand_file) and os.path.exists(pock_file)):\n",
    "        return None\n",
    "\n",
    "    data = Graph_Information(ligand_file, pock_file)\n",
    "    pickle_save = open(pickle_save, 'wb')\n",
    "    pickle.dump(data, pickle_save)\n",
    "    pickle_save.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "d = dir_\n",
    "sdfs = [d+i for i in os.listdir(d) if i.endswith('.sdf')]\n",
    "for sdf in sdfs:\n",
    "    data_list.append([sdf, f'{d}/pocket.pdb', sdf.replace('.sdf', '.pkl')])\n",
    "\n",
    "for ligand_file, pock_file, pickle_save in data_list:\n",
    "    graph_save(ligand_file, pock_file, pickle_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== input file generation =======\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "\n",
    "def input_G(d, dir_, wt=None):\n",
    "    lab = []\n",
    "    all = []\n",
    "    for n, ic in d.items():\n",
    "        all.append(dir_ + '/' + n + '.pkl')\n",
    "        lab.append(ic)\n",
    "\n",
    "        \n",
    "\n",
    "    WT = dir_ + '/' + f'A1.pkl'\n",
    "\n",
    "    N1 = []\n",
    "    N2 = []\n",
    "    L1 = []\n",
    "    L2 = []\n",
    "    L = []\n",
    "    D1 = []\n",
    "    D2 = []\n",
    "    system = []\n",
    "\n",
    "    data_list =[]\n",
    "\n",
    "    for i, pkl in enumerate(all):\n",
    "        l = lab[i]\n",
    "\n",
    "        N1.append(WT.split('/')[-1])\n",
    "        D1.append(WT)\n",
    "        N2.append(pkl.split('/')[-1])\n",
    "        D2.append(pkl)\n",
    "        L.append(l)\n",
    "\n",
    "    data_list.append(pd.DataFrame({\n",
    "                'lig1' : N1,\n",
    "                'lig2' : N2,\n",
    "                'Label' : L,\n",
    "                'Label1' : L,\n",
    "                'Label2' : L,\n",
    "                'dir_1':D1,\n",
    "                'dir_2':D2\n",
    "            }))\n",
    "\n",
    "    pd.concat(data_list).to_csv(dir_ + '/predict.csv',index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [i.split('.')[0] for i in os.listdir(dir_) if i.endswith('.pkl')]\n",
    "\n",
    "ic50 = [0 for _ in names]\n",
    "\n",
    "\n",
    "names\n",
    "\n",
    "d = dict()\n",
    "for n,ic in zip(names, ic50):\n",
    "    try:\n",
    "        ic = float(ic)\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    # ic = -np.log10(ic*1e-6)\n",
    "    d[n] = ic\n",
    "# d\n",
    "input_G(d, dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/user-home/yujie/0_PBCNetv2/0_PBCNET\n"
     ]
    }
   ],
   "source": [
    "# ========= predict =========\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "import dgl\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/user-home/yujie/0_PBCNetv2/AIcode_tensornet/\")\n",
    "from Dataloader.dataloader import LeadOptDataset\n",
    "from utilis.utilis import  pkl_load\n",
    "\n",
    "\n",
    "import dgl\n",
    "\n",
    "class LeadOptDataset():\n",
    "    def __init__(self, df_path, label_scalar=None):\n",
    "        self.df_path = df_path\n",
    "        self.df = pd.read_csv(self.df_path)\n",
    "        self.label_scalar = label_scalar\n",
    "\n",
    "        if self.label_scalar == \"finetune\":\n",
    "            label = self.df.Lable.values\n",
    "            label = (np.array(label).astype(float) - 0.04191832) / 1.34086546\n",
    "            self.df[\"Lable\"] = label\n",
    "\n",
    "        elif self.label_scalar is not None:\n",
    "            label = self.df.Lable.values\n",
    "            label = np.reshape(label, (-1, 1))\n",
    "            self.label_scalar = self.label_scalar.fit(label)\n",
    "            label = self.label_scalar.transform(label)\n",
    "            self.df[\"Lable\"] = label.flatten()\n",
    "\n",
    "        self.df = self.df\n",
    "        super(LeadOptDataset, self).__init__()\n",
    "\n",
    "            \n",
    "    def file_names_(self):\n",
    "        ligand_dir = self.df.Ligand1.values\n",
    "        file_names = [s.rsplit(\"/\", 2)[1] for s in ligand_dir]\n",
    "        return list(set(file_names))\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        return self.df[idx:idx + 1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "\n",
    "def collate_fn_acs(samples):\n",
    "    ligand1_dir = [s.dir_1.values[0] for s in samples]\n",
    "    ligand2_dir = [s.dir_2.values[0] for s in samples]\n",
    "\n",
    "    graph1_list = [pkl_load(s) for s in ligand1_dir]\n",
    "    graph2_list = [pkl_load(s) for s in ligand2_dir]\n",
    "    \n",
    "    g1 = dgl.batch(graph1_list)\n",
    "    g2 = dgl.batch(graph2_list)\n",
    "\n",
    "    label_list = [s.Label.values[0] for s in samples]  # delta\n",
    "    label1_list = [s.Label1.values[0] for s in samples]  # validation samples' labels\n",
    "    label2_list = [s.Label2.values[0] for s in samples]  # referance train samples' labels\n",
    "\n",
    "    return g1, \\\n",
    "           g2, \\\n",
    "           torch.tensor(label_list, dtype=torch.float32), \\\n",
    "           torch.tensor(label1_list, dtype=torch.float32), \\\n",
    "           torch.tensor(label2_list, dtype=torch.float32 ), \\\n",
    "           None, \\\n",
    "           None\n",
    "\n",
    "\n",
    "# def com_mean(a,idx):\n",
    "#     return np.mean(np.array(a)[idx])\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(model, loader, device):\n",
    "    # 用于预测的模块，model：训练好的模型，loader：Test data loader， device\n",
    "    model.eval()\n",
    "\n",
    "    valid_prediction = []\n",
    "    valid_labels = []\n",
    "    ref_1_labels = []  # 第一个分子是参照分子\n",
    "    valid_2_labels = []  # 第二个分子是待测分子\n",
    "\n",
    "\n",
    "    att__1 = []\n",
    "    att__2 = []\n",
    "\n",
    "    for batch_data in loader:\n",
    "        graph1, graph2, label, label1, label2, rank1, file_name = batch_data\n",
    "        # to cuda\n",
    "        graph1, graph2,  label, label1, label2 = (graph1.to(device), graph2.to(device), label.to(device), label1.to(\n",
    "            device), label2.to(device))\n",
    "\n",
    "        logits,_ = model(graph1,\n",
    "                       graph2)\n",
    "\n",
    "        valid_prediction += logits.tolist()\n",
    "\n",
    "\n",
    "        valid_labels += label.tolist()\n",
    "        ref_1_labels += label1.tolist()\n",
    "        valid_2_labels += label2.tolist()\n",
    "\n",
    "\n",
    "    mae = mean_absolute_error(valid_labels, valid_prediction)\n",
    "    rmse = mean_squared_error(valid_labels, valid_prediction) ** 0.5\n",
    "\n",
    "    # ======== to 'kcal/mol' unit =======\n",
    "    valid_labels_G = np.log(np.power(10, -np.array(valid_labels).astype(float)))*297*1.9872*1e-3\n",
    "    valid_prediction_G = np.log(np.power(10, -np.array(valid_prediction).astype(float)))*297*1.9872*1e-3\n",
    "\n",
    "    mae_g = mean_absolute_error(valid_labels_G, valid_prediction_G)\n",
    "    rmse_g = mean_squared_error(valid_labels_G, valid_prediction_G) ** 0.5\n",
    "\n",
    "    valid_prediction = np.array(valid_prediction).flatten()\n",
    "    valid_prediction_G = np.array(valid_prediction_G).flatten()\n",
    "\n",
    "    return mae, rmse, mae_g, rmse_g, valid_prediction, valid_prediction_G,np.array(valid_labels),np.array(ref_1_labels),np.array(valid_2_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_acs(logger_writer,model,device,code_path,batch_size):\n",
    "\n",
    "    rmse_gs = []\n",
    "    # load the test data\n",
    "    df_file = pd.read_csv(dir_ + \"/predict.csv\")\n",
    "\n",
    "    test_dataset = LeadOptDataset(dir_ + \"/predict.csv\")\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset,\n",
    "                                 collate_fn=collate_fn_acs,\n",
    "                                 batch_size=batch_size,\n",
    "                                 drop_last=False,\n",
    "                                 shuffle=False,\n",
    "                                 pin_memory=False)\n",
    "\n",
    "    mae,rmse,mae_g,rmse_g,valid_prediction,valid_prediction_G,valid_labels,ref_1_label,val_2_label= predict(model, test_dataloader, device)\n",
    "        \n",
    "    return valid_prediction\n",
    "\n",
    "model = torch.load(f\"{code_path}//PBCNet2.pth\", map_location=torch.device('cpu'), weights_only=False)\n",
    "\n",
    "pre = test_acs(None,model,'cpu',None,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.61251915, -0.07964045])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_file = pd.read_csv(dir_ + \"/predict.csv\")\n",
    "df_file['pre'] = pre\n",
    "df_file.to_csv(dir_ + \"/predict.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lig1</th>\n",
       "      <th>lig2</th>\n",
       "      <th>Label</th>\n",
       "      <th>Label1</th>\n",
       "      <th>Label2</th>\n",
       "      <th>dir_1</th>\n",
       "      <th>dir_2</th>\n",
       "      <th>pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1.pkl</td>\n",
       "      <td>A2.pkl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...</td>\n",
       "      <td>/home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...</td>\n",
       "      <td>1.612519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1.pkl</td>\n",
       "      <td>A1.pkl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>/home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...</td>\n",
       "      <td>/home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...</td>\n",
       "      <td>-0.079640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lig1    lig2  Label  Label1  Label2  \\\n",
       "0  A1.pkl  A2.pkl    0.0     0.0     0.0   \n",
       "1  A1.pkl  A1.pkl    0.0     0.0     0.0   \n",
       "\n",
       "                                               dir_1  \\\n",
       "0  /home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...   \n",
       "1  /home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...   \n",
       "\n",
       "                                               dir_2       pre  \n",
       "0  /home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu...  1.612519  \n",
       "1  /home/user-home/yujie/0_PBCNetv2/0_PBCNET/Resu... -0.079640  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eq2new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
